{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ced021b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "import os\n",
    "\n",
    "\n",
    "PATH = os.getcwd()\n",
    "IMG_SIZE = (160, 160)\n",
    "\n",
    "validation_dir = os.path.join(PATH, \"./test\")\n",
    "validation_dataset = image_dataset_from_directory(\n",
    "        validation_dir, shuffle=True, batch_size=203, image_size=IMG_SIZE\n",
    "    )\n",
    "val_batches = tf.data.experimental.cardinality(validation_dataset)\n",
    "test_dataset = validation_dataset.take(val_batches // 5)\n",
    "validation_dataset = validation_dataset.skip(val_batches // 5)\n",
    "\n",
    "print(\n",
    "    \"Number of validation batches: %d\"\n",
    "    % tf.data.experimental.cardinality(validation_dataset)\n",
    ")\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "validation_dataset = validation_dataset.prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1bce319",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model('./EfficientNetB0_batch32.tf')\n",
    "\n",
    "# model.load_weights('./mobilenetv2_batch32.tf')\n",
    "\n",
    "#validation_dataset = get_val_dataset()\n",
    "loss, accuracy = model.evaluate(validation_dataset)\n",
    "print(\"Test accuracy :\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ec054f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_model_dir = \"./EfficientNetB0_batch32.tf\"\n",
    "converter = tf.lite.TFLiteConverter.from_saved_model(\n",
    "    saved_model_dir, signature_keys=['serving_default'])\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "converter.experimental_new_converter = True\n",
    "converter.target_spec.supported_ops = [\n",
    "    tf.lite.OpsSet.TFLITE_BUILTINS, tf.lite.OpsSet.SELECT_TF_OPS]\n",
    "tflite_model = converter.convert()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0573da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fo = open(\n",
    "    \"./EfficientNetB0_batch32.tflite\", \"wb\")\n",
    "fo.write(tflite_model)\n",
    "fo.close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e996546a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "interpreter = tf.lite.Interpreter(model_path=\"./EfficientNetB0_batch32.tflite\")\n",
    "\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "\n",
    "input_details\n",
    "output_details\n",
    "\n",
    "input_shape = input_details[0]['shape']\n",
    "input_data = np.array(np.random.random_sample(input_shape), dtype=np.float32)\n",
    "interpreter.set_tensor(input_details[0]['index'], input_data)\n",
    "\n",
    "interpreter.invoke()\n",
    "\n",
    "output_data = interpreter.get_tensor(output_details[0]['index'])\n",
    "print(output_data)\n",
    "\n",
    "output_data\n",
    "\n",
    "tf.constant([1.0], shape=(1,10), dtype=tf.float32)\n",
    "interpreter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd829f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#mobilenetv3small\n",
    "import time\n",
    "\n",
    "n = 100\n",
    "start_time = time.time()\n",
    "for _ in range(n):\n",
    "    interpreter.invoke()\n",
    "\n",
    "print(\"FPS:\", round(n/(time.time() - start_time), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "153be4ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#mobilenetv3large\n",
    "import time\n",
    "\n",
    "n = 100\n",
    "start_time = time.time()\n",
    "for _ in range(n):\n",
    "    interpreter.invoke()\n",
    "\n",
    "print(\"FPS:\", round(n/(time.time() - start_time), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5da02c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "#mobilenetv2\n",
    "import time\n",
    "\n",
    "n = 100\n",
    "start_time = time.time()\n",
    "for _ in range(n):\n",
    "    interpreter.invoke()\n",
    "\n",
    "print(\"FPS:\", round(n/(time.time() - start_time), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7574766e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#efficientnetb0\n",
    "import time\n",
    "\n",
    "n = 100\n",
    "start_time = time.time()\n",
    "for _ in range(n):\n",
    "    interpreter.invoke()\n",
    "\n",
    "print(\"FPS:\", round(n/(time.time() - start_time), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94676816",
   "metadata": {},
   "outputs": [],
   "source": [
    "#resnet101\n",
    "import time\n",
    "\n",
    "n = 100\n",
    "start_time = time.time()\n",
    "for _ in range(n):\n",
    "    interpreter.invoke()\n",
    "\n",
    "print(\"FPS:\", round(n/(time.time() - start_time), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8c15692",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:img-cap] *",
   "language": "python",
   "name": "conda-env-img-cap-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
